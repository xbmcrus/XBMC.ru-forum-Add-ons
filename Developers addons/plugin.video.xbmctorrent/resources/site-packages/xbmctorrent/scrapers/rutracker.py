#!/usr/bin/python
# -*- coding: utf-8 -*-

import sys
from xbmcswift2 import actions
from xbmctorrent import plugin
from xbmctorrent.scrapers import scraper
from xbmctorrent.ga import tracked
from xbmctorrent.caching import cached_route
from xbmctorrent.utils import ensure_fanart
import xbmcgui
from traceback import format_exc
import re
BASE_URL = "http://rutracker.org/forum/"
LOGIN_URL = "http://login.rutracker.org/forum/login.php"

HEADERS = {
    'Referer': BASE_URL,
    'Accept': 'text/html, application/xml, application/xhtml+xml, image/png, image/jpeg, image/gif, image/x-xbitmap, */*',
    'Accept-Language': 'ru-RU,ru;q=0.9,en;q=0.8',
    'Accept-Charset': 'utf-8, *;q=0.1',
    'Accept-Encoding': 'identity, *;q=0'
}

topic_id_parser = re.compile(r'\?t=(\d*)$', re.U)
search_id_parser = re.compile(r'\?id=(.*)\&', re.U)

CATEGORIES = (
    ("7", u"Зарубежные фильмы", "movies", "tmdb"),
    ("22", u"Наши фильмы", "movies", "kinopoisk"),
    ("189", u"Зарубежные Сериалы", "tvshows", "tvdb"),
    ("9", u"Русскоязычные сериалы", "tvshows", "tvdb"),
    ("46", u"Документальные фильмы и телепередачи", "movies", ""),
    ("24", u"Развлекательные телепередачи и шоу, приколы и юмор", "tvshows", ""),
    ("4", u"Мультипликация", "movies", "tmdb"),
    # ("10", u"Аниме", "movies", ""),
    # ("13", u"Спорт и Здоровье", "tvshows", ""),
    # ("15", u"Юмор", "tvshows", ""),
    # ("14", u"Хозяйство и Быт", "tvshows", ""),
)

# Cache TTLs
DEFAULT_TTL = 300  # 5 minutes

IGNORE = [u"Repack", u" PC |", u" РС", u" PC", u" PS", u"XBOX", u"RePack", u"FB2", u"TXT", u"DOC", u" MP3", u" JPG",
          u" PNG", u" SCR", u"PDF"]
IGNORE_EXT = [u".srt", u".ssa", u".txt", u".ac3", u".aac", u".jpg"]


def udec(x):
    return x.decode('utf-8')


def uenc(x):
    return x.encode('utf-8')


_cookiejar = None


@scraper("Rutracker.org", "http://195.82.146.52/logo/logo.gif", plugin.get_setting("rutracker_enabled", bool))
@plugin.route("/rutracker")
@ensure_fanart
def rutracker_index():
    for cat in CATEGORIES:
        yield {
            "label": cat[1],
            "path": plugin.url_for("rutracker_page", catind=cat[0], page=0, query=cat[0]),
        }


@plugin.route("/rutracker/browse/<catind>/<page>/<query>")
@cached_route(ttl=DEFAULT_TTL, content_type="movies")
@ensure_fanart
def rutracker_page(catind, page, query=None):
    import urllib, xbmc
    from bs4 import BeautifulSoup, SoupStrainer
    from urlparse import urljoin
    from contextlib import closing
    from itertools import izip
    from concurrent import futures
    from multiprocessing.pool import ThreadPool
    from xbmctorrent.utils import terminating, SafeDialogProgress
    from urlparse import urlparse

    scraper_name = ""
    category = ([cat for cat in CATEGORIES if cat[0] == catind] or [("0", u"", "", "")])[0]
    scraper_name = category[3]
    plugin.set_content(category[2])
    page = int(page)

    with closing(SafeDialogProgress(delay_close=0)) as dialog:
        dialog.create(plugin.name)
        dialog.update(percent=0, line1=u"Получение информации о раздачах...", line2="", line3="")

        items = []
        try:
            start_index = 0
            url = urljoin(BASE_URL, "viewforum.php?f=%s&start=%s" % (query, str(page * 50)))
            html_data = url_get(url, headers=HEADERS)
            soup = BeautifulSoup(html_data, "html5lib")
            # find subforums
            nodes = soup.findAll("h4", class_=["forumlink"])

            #Add search item on topmost page:
            if catind == query:
                yield {
                    "label": u"[COLOR FFFFFF00][ Поиск ][/COLOR]",
                    "path": plugin.url_for("rutracker_search", catind=catind),
                }

            plugin.log.debug("Loading forum nodes")
            for node in nodes:
                link = node.find("a")
                plugin.log.debug("Forum link: " + str(link))
                link_href = link["href"]
                # find forum id in href:
                forumid = int(link_href[link_href.find(u"=") + 1:len(link_href)])
                item = {
                    "label": link.text,
                    "path": plugin.url_for("rutracker_page", catind=catind, page=0, query=forumid),
                    "info": {"title": link.text},
                    "is_playable": False,
                }
                yield item

            nodes = soup.findAll("td", class_=["topic_id"])

            for node in nodes:
                id = node["id"]
                title_node = node.parent.find(id='tt-%s' % str(id))
                title = _rutracker_cleantitle(title_node.text)
                row_node = node.parent \
                    #find "size" table cell - it should have download link
                size_td = row_node.find_all("td")[2]

                #check if size node has download link to torrent file:
                if size_td:
                    size_link = size_td.find("a", class_=["small"])
                    if size_link:
                        size = size_link.text
                        seeds = size_td.find("span", class_=["seedmed"]).b.text
                        peers = size_td.find("span", class_=["leechmed"]).b.text
                        size = size_td.find("a", class_=["small"]).text
                        label = "%s | %s (S:%s P:%s)" % ( title, size, seeds, peers)
                        item = {
                            "label": label,
                            "path": plugin.url_for("rutracker_play", tid=id),
                            "info": {"title": title},
                            "is_playable": False,
                            "context_menu": [
                                ("Play with Pulsar", actions.update_view(plugin.url_for("rutracker_play_pulsar", tid=id)))
                            ]
                        }
                        items.append(item)
                        plugin.log.debug("Item added: " + title.encode('utf-8'))
        except:

            plugin.log.error("Unexpected error: %s" % format_exc().split('\n')[-2])
            xbmcgui.Dialog().ok(plugin.name, "Не удалось получить данные от сервера")
            return

        def _get_torrent_info(item):

            from xbmctorrent.search import scrapers as search
            from xbmctorrent.utils import get_quality_from_name

            try:
                scrapers = search.Scrapers()
                if not plugin.get_setting("rutracker_usesearch", bool):
                    meta = scrapers.default(item)
                else:
                    meta = scrapers.scraper(scraper_name, item)

                meta["path"] = item["path"]
                meta["is_playable"] = item["is_playable"]
                meta.setdefault("stream_info", {}).update(get_quality_from_name(meta['label']))
                return meta
            except:
                plugin.log.error("Unexpected error: %s" % format_exc().split('\n')[-2])
                return scrapers.default(item)

        state = {"done": 0}

        def on_done(data):
            state["done"] += 1
            dialog.update(
                percent=int(state["done"] * 100.0 / len(items)),
                line2=data["info"].get("title") or data.get("label") or "",
            )

        with terminating(ThreadPool(5)) as pool:
            jobs = [pool.apply_async(_get_torrent_info, [item], callback=on_done) for item in items]
            while not all(job.ready() for job in jobs):
                if dialog.iscanceled():
                    return
                xbmc.sleep(100)

        for job in jobs:
            item = job.get()
            del item["search"]
            del item["subdir"]
            yield item

        next_page = {
            "label": u"[Далее >]",
            "path": plugin.url_for("rutracker_page", catind=catind, page=page + 1, query=query),
            "is_playable": False,
        }
        yield next_page


@plugin.route("/rutracker/search/<catind>/<page>/<search>")
@cached_route(ttl=DEFAULT_TTL, content_type="movies")
@ensure_fanart
def rutracker_search_page(catind, page, search=None, search_id = None):
    import urllib, xbmc
    from bs4 import BeautifulSoup, SoupStrainer
    from urlparse import urljoin
    from contextlib import closing
    from itertools import izip
    from concurrent import futures
    from multiprocessing.pool import ThreadPool
    from xbmctorrent.utils import terminating, SafeDialogProgress
    from urlparse import urlparse

    scraper_name = ""
    category = ([cat for cat in CATEGORIES if cat[0] == catind] or [("0", u"", "", "")])[0]
    scraper_name = category[3]
    plugin.set_content(category[2])
    if plugin.request.args.get("search_id"):
        search_id = plugin.request.args.get("search_id")[0]
    page = int(page)
    catind = int(catind)

    with closing(SafeDialogProgress(delay_close=0)) as dialog:
        dialog.create(plugin.name)
        dialog.update(percent=0, line1=u"Получение информации о раздачах...", line2="", line3="")

        items = []
        try:
            start_index = 0
            url = urljoin(BASE_URL, "search.php?")

            if search_id:
                params = {}
                params["nm"] = search
                if int(page) > 0:
                    params["start"] = int(page) * 50
                params["id"] = search_id
                html_data = url_get(url, headers=HEADERS, params = params)
            else:
                post_body = {"nm": search, "fsf": catind}
                html_data = url_get(url, headers=HEADERS, post = post_body)

            soup = BeautifulSoup(html_data, "html5lib")

            node = soup.find("a", class_ =["pg"])
            if node:
                r = search_id_parser.search(node['href'])
                if r:
                    plugin.log.debug("Search id found: " + str(r.group(1)))
                    search_id = str(r.group(1))

            nodes = soup.findAll("a", class_=["topictitle"])

            for link in nodes:
                try:
                    title = _rutracker_cleantitle(link.text)
                    r = topic_id_parser.search(link['href'])
                    if r:
                        id = r.group(1)
                        label = "%s" % ( title)
                        item = {
                            "label": label,
                            "path": plugin.url_for("rutracker_play", tid=id),
                            "info": {"title": title},
                            "is_playable": False,
                            "context_menu": [
                                ("Play with Pulsar", actions.update_view(plugin.url_for("rutracker_play_pulsar", tid=id)))
                            ]
                        }
                        items.append(item)
                        plugin.log.debug("Item added: " + title.encode('utf-8'))
                except:
                    plugin.log.error("Unexpected error: %s \r Skipping item" % format_exc().split('\n')[-2])
        except:
            plugin.log.error("Unexpected error: %s" % format_exc().split('\n')[-2])
            xbmcgui.Dialog().ok(plugin.name, "Не удалось получить данные от сервера")
            return

        def _get_torrent_info(item):

            from xbmctorrent.search import scrapers as search
            from xbmctorrent.utils import get_quality_from_name

            try:
                scrapers = search.Scrapers()
                if not plugin.get_setting("rutracker_usesearch", bool):
                    meta = scrapers.default(item)
                else:
                    meta = scrapers.scraper(scraper_name, item)
                plugin.log.debug("RUTRACKER: Meta information received")
                meta["path"] = item["path"]
                meta["is_playable"] = item["is_playable"]
                meta.setdefault("stream_info", {}).update(get_quality_from_name(meta['label']))
                plugin.log.debug("RUTRACKER: Meta path updated")
                return meta
            except:
                plugin.log.error("RUTRACKER: Unexpected error: %s parsing item [%s]" % (format_exc().split('\n')[-2],str(item)))
                return scrapers.default(item)

        state = {"done": 0}

        def on_done(data):
            state["done"] += 1
            dialog.update(
                percent=int(state["done"] * 100.0 / len(items)),
                line2=data["info"].get("title") or data.get("label") or "",
            )

        with terminating(ThreadPool(5)) as pool:
            jobs = [pool.apply_async(_get_torrent_info, [item], callback=on_done) for item in items]
            while not all(job.ready() for job in jobs):
                if dialog.iscanceled():
                    return
                xbmc.sleep(100)

        for job in jobs:
            try:
                item = job.get()
                del item["search"]
                del item["subdir"]
                yield item
            except:
                plugin.log.error("RUTRACKER: Unexpected error: %s parsing item [%s]" % (format_exc().split('\n')[-2],str(item)))
        if search_id:
            next_page = {
                "label": u"[Далее >]",
                "path": plugin.url_for("rutracker_search_page", catind=catind, page=page + 1, search=search,search_id = search_id),
                "is_playable": False,
            }
            yield next_page


@plugin.route("/rutracker/search/<catind>")
def rutracker_search(catind):
    import urllib

    query = plugin.request.args.get("query")
    if query:
        query = query[0]
    else:
        query = plugin.keyboard("", "Rutracker.org - Search")

    if query:
        plugin.redirect(plugin.url_for("rutracker_search_page", catind=catind, page=0, search=query))


@plugin.route("/rutracker/play/<tid>", options={"pulsar":"0"})
@plugin.route("/rutracker/play/pulsar/<tid>", name="rutracker_play_pulsar", options={"pulsar":"1"})
@ensure_fanart
def rutracker_play(tid, pulsar):
    from copy import deepcopy
    from contextlib import closing
    from bencode import bencode, bdecode
    from urlparse import urljoin
    from xbmctorrent.magnet import generate_magnet
    from xbmctorrent.utils import first, SafeDialogProgress, get_quality_from_name, get_current_list_item
    from xbmctorrent.acestream import ace_supported

    with closing(SafeDialogProgress(delay_close=0)) as dialog:
        dialog.create(plugin.name)
        dialog.update(percent=0, line1="Получение информации о раздаче...")

        torrent_url = urljoin("http://dl.rutracker.org/forum/", "dl.php?t=%s" % tid)
        try:

            plugin.log.debug("loading data from uri: " + torrent_url)
            params = {"t": tid}

            import os, xbmc, cookielib


            cookie = cookielib.Cookie(version=0, name='bb_dl', value=tid, port=None, port_specified=False,
                                      domain='.rutracker.org', domain_specified=False, domain_initial_dot=False,
                                      path='/', path_specified=True, secure=False, expires=None, discard=True,
                                      comment=None, comment_url=None, rest={'HttpOnly': None}, rfc2109=False)

            data = url_get(torrent_url, headers=HEADERS, post=params, cookie=cookie)
            metadata = bdecode(data)
            plugin.log.debug("Metadata received " + str(metadata))
        except:
            import xbmcgui

            plugin.log.error("Unexpected error: %s " % format_exc().split('\n')[-2])
            xbmcgui.Dialog().ok(plugin.name, "Не удалось получить данные от сервера")
            return

        dialog.update(percent=100, line1="Готово")

        # Get currently selected item
        current_item = get_current_list_item()
        current_item.setdefault("stream_info", {}).update(get_quality_from_name(current_item['label']))

        if "files" in metadata["info"] and ace_supported():
            items = {}
            for index, info in enumerate(metadata["info"]["files"]):
                name = "/".join(info["path"])

                if not _rutracker_valid_file(name):
                    continue

                items[index] = deepcopy(current_item)
                items[index].update({
                    "label": name,
                    "path": plugin.url_for("play_torrent_raw", raw=data, index=index, name=name),
                    "is_playable": True
                })
                items[index].setdefault("info", {}).update({
                    "title": name,
                })

            # start playback if torrent contains only one file
            if len(items) == 1:
                index, item = items.popitem()

                if not plugin.get_setting("force_ace", bool):
                    item["path"] = plugin.url_for("play", uri=generate_magnet(metadata, item["label"]))

                plugin.play_video(item)
                yield item
            else:
                plugin.add_sort_method('label')
                for i in items.values():
                    yield i
        else:
            name = metadata["info"].get("name") or " / ".join(first(metadata["info"]["files"])["path"]) or "rutor.org"
            if plugin.get_setting("force_ace", bool) and ace_supported():
                current_item["path"] = plugin.url_for("play_torrent_raw", raw=data, index=0, name=name)
            else:
				current_item["path"] = plugin.url_for(["play","play_with_pulsar"][int(pulsar)], uri=generate_magnet(metadata, name))

            current_item["is_playable"] = True
            plugin.play_video(current_item)

            yield current_item


def _rutracker_valid_file(filename):
    for exclude in IGNORE_EXT:
        if filename.decode("utf-8").endswith(exclude):
            return False
    return True


def _rutracker_cleantitle(title):
    # k1=title.find('/')
    #if k1<0: k1=title.find('(')
    k1 = title.find('(')
    tmp1 = title[:k1]
    n1 = -1
    if tmp1.find('[') < 0:
        n1 = title.find('[')
    if n1 < 0:
        n1 = title.find('(')
    k2 = title.find(u" от ")
    if k2 < 0:
        k2 = None
    tmp2 = title[n1:k2]
    title = tmp1 + tmp2
    title = title.replace(u"| Лицензия", "")
    title = title.replace(u"| лицензия", "")
    title = title.replace(u"| ЛицензиЯ", "")
    return title.strip()


def _rutracker_login(_cookiejar):
    from xbmctorrent.utils import url_get as url_get_origin
    import urllib2

    values = {
        "login_username": plugin.get_setting("rutracker_login"),
        "login_password": plugin.get_setting("rutracker_passw"),
        'login': 'Вход'
    }

    plugin.log.debug("Login user")
    HEADERS["Referer"] = LOGIN_URL
    HEADERS["Content-Type"] = "application/x-www-form-urlencoded"

    cookie_handler = urllib2.HTTPCookieProcessor(_cookiejar)

    html = url_get_origin(LOGIN_URL, post=values, headers=HEADERS, handlers=[cookie_handler])
    if html.find("profile.php?mode=sendpassword") >= 0:
        plugin.notify("Проверьте настройки авторизации.", delay=15000)
    else:
        plugin.log.debug("Login sucessfull")
        return True
    _cookiejar.save()
    HEADERS["Referer"] = BASE_URL  # restore referer
    return False


def url_get(url, params={}, headers={}, post=None, cookie=None):
    global _cookiejar
    import xbmcvfs, urllib2
    from xbmctorrent.utils import url_get as url_get_origin

    if not _cookiejar:
        import os, xbmc, cookielib

        sid_file = os.path.join(xbmc.translatePath('special://temp/'), plugin.id, 'LostFilm.cookies.dat')  #
        if not xbmcvfs.exists(os.path.dirname(sid_file)):
            xbmcvfs.mkdir(os.path.dirname(sid_file))

        _cookiejar = cookielib.MozillaCookieJar(sid_file)

        if not xbmcvfs.exists(sid_file):
            _cookiejar.save()

        _cookiejar.load()

    if cookie:
        _cookiejar.set_cookie(cookie)
    cookie_handler = urllib2.HTTPCookieProcessor(_cookiejar)
    plugin.log.debug("Loading uri: %s with cookies %s params %s post %s" % (url, _cookiejar,str(params), str(post)))
    result = url_get_origin(url, params, headers, post, handlers=[cookie_handler])
    _cookiejar.save()
    plugin.log.debug("Uri loaded: " + url)

    if result.find("profile.php?mode=sendpassword") >= 0:
        if not plugin.get_setting("rutracker_login") and not plugin.get_setting("rutracker_passwd"):
            plugin.notify("Проверьте настройки авторизации.", delay=15000)
            return
        if _rutracker_login(_cookiejar):
            result = url_get_origin(url, params, headers, post, handlers=[cookie_handler])
            _cookiejar.save()

    return result